{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb73a1b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:38.106519Z",
     "iopub.status.busy": "2024-12-10T01:00:38.106193Z",
     "iopub.status.idle": "2024-12-10T01:00:38.903909Z",
     "shell.execute_reply": "2024-12-10T01:00:38.902973Z"
    },
    "papermill": {
     "duration": 0.807205,
     "end_time": "2024-12-10T01:00:38.906390",
     "exception": false,
     "start_time": "2024-12-10T01:00:38.099185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/README (1).md\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/tokenizer_config (1).json\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/special_tokens_map.json\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/added_tokens.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/tokenizer.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/special_tokens_map.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/added_tokens.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/trainer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/tokenizer.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/special_tokens_map.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/added_tokens.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/run_test.sh\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/run_train.sh\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/trainer_state.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/eval_results.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/training_args.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/tokenizer.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/all_results.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/special_tokens_map.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/added_tokens.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/test_results.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/trainer_state.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/training_args.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/tokenizer.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/scaler.pt\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/scheduler.pt\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/special_tokens_map.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/optimizer.pt\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/rng_state.pth\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/added_tokens.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/rust_model.ot\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/tf_model.h5\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/pytorch_model.generator.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/tf_model.h5\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/generator_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/tf_model.h5\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/tf_model.h5\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/tf_model.h5\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/gitattributes.txt\n",
      "/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased/config.json\n",
      "/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased/README.md\n",
      "/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased/tf_model.h5\n",
      "/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased/tokenizer_config.json\n",
      "/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased/gitattributes\n",
      "/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased/pytorch_model.bin\n",
      "/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased/model.safetensors\n",
      "/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased/special_tokens_map.json\n",
      "/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased/vocab.txt\n",
      "/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased/flax_model.msgpack\n",
      "/kaggle/input/eedi-mining-misconceptions-in-mathematics/sample_submission.csv\n",
      "/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\n",
      "/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\n",
      "/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\n",
      "/kaggle/input/roberta-base/rust_model.ot\n",
      "/kaggle/input/roberta-base/config.json\n",
      "/kaggle/input/roberta-base/merges.txt\n",
      "/kaggle/input/roberta-base/README.md\n",
      "/kaggle/input/roberta-base/tokenizer.json\n",
      "/kaggle/input/roberta-base/vocab.json\n",
      "/kaggle/input/roberta-base/dict.txt\n",
      "/kaggle/input/roberta-base/gitattributes\n",
      "/kaggle/input/roberta-base/pytorch_model.bin\n",
      "/kaggle/input/roberta-base/model.safetensors\n",
      "/kaggle/input/roberta-base/flax_model.msgpack\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d4b3f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:38.919218Z",
     "iopub.status.busy": "2024-12-10T01:00:38.918854Z",
     "iopub.status.idle": "2024-12-10T01:00:57.307520Z",
     "shell.execute_reply": "2024-12-10T01:00:57.306805Z"
    },
    "papermill": {
     "duration": 18.397769,
     "end_time": "2024-12-10T01:00:57.309566",
     "exception": false,
     "start_time": "2024-12-10T01:00:38.911797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "from transformers import AdamW, get_scheduler, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7900eec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:57.321366Z",
     "iopub.status.busy": "2024-12-10T01:00:57.320833Z",
     "iopub.status.idle": "2024-12-10T01:00:57.393718Z",
     "shell.execute_reply": "2024-12-10T01:00:57.392808Z"
    },
    "papermill": {
     "duration": 0.081075,
     "end_time": "2024-12-10T01:00:57.395881",
     "exception": false,
     "start_time": "2024-12-10T01:00:57.314806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536ea2cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:57.407466Z",
     "iopub.status.busy": "2024-12-10T01:00:57.407187Z",
     "iopub.status.idle": "2024-12-10T01:00:57.470327Z",
     "shell.execute_reply": "2024-12-10T01:00:57.469363Z"
    },
    "papermill": {
     "duration": 0.071271,
     "end_time": "2024-12-10T01:00:57.472388",
     "exception": false,
     "start_time": "2024-12-10T01:00:57.401117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_actual = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\n",
    "real_test_df = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n",
    "misconception_df = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ad4511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:57.484207Z",
     "iopub.status.busy": "2024-12-10T01:00:57.483891Z",
     "iopub.status.idle": "2024-12-10T01:00:57.497792Z",
     "shell.execute_reply": "2024-12-10T01:00:57.497008Z"
    },
    "papermill": {
     "duration": 0.021703,
     "end_time": "2024-12-10T01:00:57.499479",
     "exception": false,
     "start_time": "2024-12-10T01:00:57.477776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1349, Validation size: 239, Test size: 281\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test, and validation\n",
    "train_df, test_df = train_test_split(train_df_actual, test_size=0.15, random_state=42)  # 15% for testing\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=42)  # 15% of remaining for validation\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}, Test size: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26db538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:57.511041Z",
     "iopub.status.busy": "2024-12-10T01:00:57.510790Z",
     "iopub.status.idle": "2024-12-10T01:00:57.516452Z",
     "shell.execute_reply": "2024-12-10T01:00:57.515793Z"
    },
    "papermill": {
     "duration": 0.013063,
     "end_time": "2024-12-10T01:00:57.517909",
     "exception": false,
     "start_time": "2024-12-10T01:00:57.504846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to preprocess LaTeX into plain text\n",
    "def preprocess_latex_to_text(latex_str):\n",
    "    # Handle common LaTeX functions and symbols\n",
    "    latex_str = latex_str.replace(r'\\frac', 'over')  # Convert fractions\n",
    "    latex_str = latex_str.replace(r'\\sum', 'sum')  # Convert summation symbol\n",
    "    latex_str = latex_str.replace(r'\\int', 'integral')  # Convert integral symbol\n",
    "    latex_str = latex_str.replace(r'\\sqrt', 'square root')  # Convert square root\n",
    "    latex_str = latex_str.replace(r'\\text', '')  # Remove text formatting in LaTeX\n",
    "    \n",
    "    # Handle superscripts and subscripts (e.g., x^2 or x_1)\n",
    "    latex_str = re.sub(r'\\^{(.*?)}', r' raised to \\1', latex_str)  # e.g., x^{2} becomes x raised to 2\n",
    "    latex_str = re.sub(r'_{(.*?)}', r' sub \\1', latex_str)  # e.g., x_{1} becomes x sub 1\n",
    "    \n",
    "    # Remove other LaTeX math environments (e.g., dollar signs for inline math)\n",
    "    latex_str = latex_str.replace('$', '')\n",
    "    \n",
    "    # Optionally, remove other LaTeX-specific symbols or escape characters\n",
    "    latex_str = latex_str.replace(r'\\\\', '')  # Remove LaTeX newlines\n",
    "    latex_str = latex_str.replace(r'{', ' ').replace(r'}', ' ')  # Remove curly braces\n",
    "    latex_str = ' '.join(latex_str.split())  # Clean up extra spaces\n",
    "    \n",
    "    return latex_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97fcaeda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:57.528808Z",
     "iopub.status.busy": "2024-12-10T01:00:57.528557Z",
     "iopub.status.idle": "2024-12-10T01:00:57.533354Z",
     "shell.execute_reply": "2024-12-10T01:00:57.532658Z"
    },
    "papermill": {
     "duration": 0.012187,
     "end_time": "2024-12-10T01:00:57.535006",
     "exception": false,
     "start_time": "2024-12-10T01:00:57.522819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine question and answer text\n",
    "def preprocess_data(df):\n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        for option in [\"A\", \"B\", \"C\", \"D\"]:  # Only incorrect answers\n",
    "            # if row['CorrectAnswer'] != option:\n",
    "            input_text = f\"Question: {row['QuestionText']} | Answer: {row[f'Answer{option}Text']}\"\n",
    "            input_text = preprocess_latex_to_text(input_text)\n",
    "            label = row[f\"Misconception{option}Id\"]\n",
    "            questionid = f\"{row['QuestionId']}\"\n",
    "            answer = f\"{option}\"\n",
    "            data.append((questionid, answer, input_text, label))\n",
    "    return pd.DataFrame(data, columns=[\"QuestionId\",\"Answer\", \"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b85f37c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:57.546678Z",
     "iopub.status.busy": "2024-12-10T01:00:57.546146Z",
     "iopub.status.idle": "2024-12-10T01:00:57.550041Z",
     "shell.execute_reply": "2024-12-10T01:00:57.549371Z"
    },
    "papermill": {
     "duration": 0.011591,
     "end_time": "2024-12-10T01:00:57.551603",
     "exception": false,
     "start_time": "2024-12-10T01:00:57.540012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MisconceptionDataset(Dataset):\n",
    "#     def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "#         self.texts = texts\n",
    "#         self.labels = labels\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         text = self.texts[idx]\n",
    "#         label = self.labels[idx]\n",
    "\n",
    "#         # Assuming `text` has two parts: question and answer\n",
    "#         question, answer = text.split(\" | Answer: \")\n",
    "\n",
    "#         # Tokenize with [CLS] and [SEP] tokens\n",
    "#         tokens = self.tokenizer(\n",
    "#             question,\n",
    "#             answer,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors=\"pt\",\n",
    "#             return_special_tokens_mask=True,  # Helps ensure correct use of [SEP]\n",
    "#         )\n",
    "#         return {\n",
    "#             \"input_ids\": tokens[\"input_ids\"].squeeze(),\n",
    "#             \"attention_mask\": tokens[\"attention_mask\"].squeeze(),\n",
    "#             \"labels\": torch.tensor(label, dtype=torch.float),\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72deb4a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:57.562569Z",
     "iopub.status.busy": "2024-12-10T01:00:57.562333Z",
     "iopub.status.idle": "2024-12-10T01:00:57.569440Z",
     "shell.execute_reply": "2024-12-10T01:00:57.568780Z"
    },
    "papermill": {
     "duration": 0.014419,
     "end_time": "2024-12-10T01:00:57.571023",
     "exception": false,
     "start_time": "2024-12-10T01:00:57.556604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MisconceptionDataset(Dataset):\n",
    "    def __init__(self, question_ids, answer_labels, texts, labels, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            question_ids (list): List of Question IDs.\n",
    "            answer_labels (list): List of Answer Labels (e.g., A, B, C, D).\n",
    "            texts (list): List of question texts.\n",
    "            labels (list): List of true Misconception IDs.\n",
    "            tokenizer (transformers tokenizer): Tokenizer to encode the text.\n",
    "            max_length (int, optional): Max sequence length for tokenization. Defaults to 512.\n",
    "        \"\"\"\n",
    "        self.question_ids = question_ids\n",
    "        self.answer_labels = answer_labels\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question_id = self.question_ids[idx]\n",
    "        answer_label = self.answer_labels[idx]\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Assuming `text` has two parts: question and answer\n",
    "        question, answer = text.split(\" | Answer: \")\n",
    "        question = question.split(\"Question: \")[1]\n",
    "\n",
    "        # Tokenize with [CLS] and [SEP] tokens\n",
    "        tokens = self.tokenizer(\n",
    "            question,\n",
    "            answer,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "            return_special_tokens_mask=True,  # Helps ensure correct use of [SEP]\n",
    "        )\n",
    "        \n",
    "        # # Assuming the `text` is just the question text; answer is inferred from `answer_label`\n",
    "        # question = text  # In case answer text is separate, modify as needed\n",
    "\n",
    "        # # Tokenize the question text\n",
    "        # tokens = self.tokenizer(\n",
    "        #     question,\n",
    "        #     padding=\"max_length\",\n",
    "        #     truncation=True,\n",
    "        #     max_length=self.max_length,\n",
    "        #     return_tensors=\"pt\",\n",
    "        #     return_special_tokens_mask=True,  # Ensures correct use of [SEP]\n",
    "        # )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": tokens[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": tokens[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.float),\n",
    "            \"QuestionId\": question_id,  # Include the Question ID\n",
    "            \"AnswerLabel\": answer_label  # Include the Answer label (A, B, C, D)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fddf940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:57.581904Z",
     "iopub.status.busy": "2024-12-10T01:00:57.581643Z",
     "iopub.status.idle": "2024-12-10T01:00:57.866280Z",
     "shell.execute_reply": "2024-12-10T01:00:57.865483Z"
    },
    "papermill": {
     "duration": 0.292058,
     "end_time": "2024-12-10T01:00:57.868144",
     "exception": false,
     "start_time": "2024-12-10T01:00:57.576086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>Answer</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: Without using a calculator, which tw...</td>\n",
       "      <td>734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1043</td>\n",
       "      <td>D</td>\n",
       "      <td>Question: Which signs belong in the boxes to m...</td>\n",
       "      <td>2030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1340</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: A square has an area of \\( 100 \\math...</td>\n",
       "      <td>1678.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1340</td>\n",
       "      <td>C</td>\n",
       "      <td>Question: A square has an area of \\( 100 \\math...</td>\n",
       "      <td>734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>586</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: Simplify \\( square root 48 \\) as muc...</td>\n",
       "      <td>2384.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId Answer                                               text  \\\n",
       "0         368      A  Question: Without using a calculator, which tw...   \n",
       "7        1043      D  Question: Which signs belong in the boxes to m...   \n",
       "8        1340      A  Question: A square has an area of \\( 100 \\math...   \n",
       "10       1340      C  Question: A square has an area of \\( 100 \\math...   \n",
       "12        586      A  Question: Simplify \\( square root 48 \\) as muc...   \n",
       "\n",
       "     label  \n",
       "0    734.0  \n",
       "7   2030.0  \n",
       "8   1678.0  \n",
       "10   734.0  \n",
       "12  2384.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess data\n",
    "train_data = preprocess_data(train_df)\n",
    "val_data = preprocess_data(val_df)\n",
    "test_data = preprocess_data(test_df)\n",
    "\n",
    "train_data.dropna(inplace = True)\n",
    "val_data.dropna(inplace = True)\n",
    "test_data.dropna(inplace = True)\n",
    "\n",
    "# # Combine into DataFrames\n",
    "# train_data = pd.DataFrame(train_data, columns=[\"text\", \"label\"])\n",
    "# val_data = pd.DataFrame(val_data, columns=[\"text\", \"label\"])\n",
    "# test_data = pd.DataFrame(test_data, columns=[\"text\", \"label\"])\n",
    "\n",
    "# Convert labels to multi-hot encoding\n",
    "all_labels = sorted(misconception_df[\"MisconceptionId\"].unique())  # Get all unique labels\n",
    "mlb = MultiLabelBinarizer(classes=all_labels)\n",
    "\n",
    "train_labels = mlb.fit_transform([[label] for label in train_data[\"label\"]])\n",
    "val_labels = mlb.transform([[label] for label in val_data[\"label\"]])\n",
    "test_labels = mlb.transform([[label] for label in test_data[\"label\"]])\n",
    "\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c5122bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:57.890478Z",
     "iopub.status.busy": "2024-12-10T01:00:57.889723Z",
     "iopub.status.idle": "2024-12-10T01:00:57.894786Z",
     "shell.execute_reply": "2024-12-10T01:00:57.893564Z"
    },
    "papermill": {
     "duration": 0.014454,
     "end_time": "2024-12-10T01:00:57.896353",
     "exception": false,
     "start_time": "2024-12-10T01:00:57.881899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3160, Validation size: 555, Test size: 655\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_data)}, Validation size: {len(val_data)}, Test size: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0071de1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:57.908673Z",
     "iopub.status.busy": "2024-12-10T01:00:57.908424Z",
     "iopub.status.idle": "2024-12-10T01:00:59.373512Z",
     "shell.execute_reply": "2024-12-10T01:00:59.372740Z"
    },
    "papermill": {
     "duration": 1.473204,
     "end_time": "2024-12-10T01:00:59.375667",
     "exception": false,
     "start_time": "2024-12-10T01:00:57.902463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46c68d41c834cdfb7887c967ef904b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c915aeb68c41ff8cc70e4983c8f518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb2670858db45cfadf5efcf0ed2a46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create datasets\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "train_dataset = MisconceptionDataset(train_data[\"QuestionId\"].tolist(), train_data[\"Answer\"].tolist(), train_data[\"text\"].tolist(), train_labels, tokenizer)\n",
    "val_dataset = MisconceptionDataset(val_data[\"QuestionId\"].tolist(), val_data[\"Answer\"].tolist(), val_data[\"text\"].tolist(), val_labels, tokenizer)\n",
    "test_dataset = MisconceptionDataset(test_data[\"QuestionId\"].tolist(), test_data[\"Answer\"].tolist(), test_data[\"text\"].tolist(), test_labels, tokenizer)\n",
    "\n",
    "# DataLoader for batching\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67fdbe57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:00:59.388498Z",
     "iopub.status.busy": "2024-12-10T01:00:59.388186Z",
     "iopub.status.idle": "2024-12-10T01:01:04.182271Z",
     "shell.execute_reply": "2024-12-10T01:01:04.181390Z"
    },
    "papermill": {
     "duration": 4.802577,
     "end_time": "2024-12-10T01:01:04.184114",
     "exception": false,
     "start_time": "2024-12-10T01:00:59.381537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459bebc44ba4438da15fd4e6457d2dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "# Model\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=len(all_labels), ignore_mismatched_sizes=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "num_training_steps = len(train_dataloader) * 10  # 10 epochs\n",
    "# scheduler = get_scheduler(\"linear\", optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "# scheduler = get_scheduler('cosine_annealing_lr', optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "# scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_training_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(0.1 * num_training_steps), num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47794569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:01:04.197160Z",
     "iopub.status.busy": "2024-12-10T01:01:04.196901Z",
     "iopub.status.idle": "2024-12-10T01:01:04.201054Z",
     "shell.execute_reply": "2024-12-10T01:01:04.200222Z"
    },
    "papermill": {
     "duration": 0.012539,
     "end_time": "2024-12-10T01:01:04.202707",
     "exception": false,
     "start_time": "2024-12-10T01:01:04.190168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Change the loss calculation in training and evaluation loops\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3a0a1e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:01:04.215278Z",
     "iopub.status.busy": "2024-12-10T01:01:04.214982Z",
     "iopub.status.idle": "2024-12-10T01:01:04.221787Z",
     "shell.execute_reply": "2024-12-10T01:01:04.221052Z"
    },
    "papermill": {
     "duration": 0.014854,
     "end_time": "2024-12-10T01:01:04.223457",
     "exception": false,
     "start_time": "2024-12-10T01:01:04.208603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_precision_at_k(predictions, true_labels, k):\n",
    "    \"\"\"\n",
    "    Calculate Precision at rank k.\n",
    "    predictions: List of predicted MisconceptionId(s) for a particular QuestionId_Answer.\n",
    "    true_labels: Set of correct MisconceptionId(s) for the same QuestionId_Answer.\n",
    "    k: The rank at which precision is calculated.\n",
    "    \"\"\"\n",
    "    relevant = sum([1 for pred in predictions[:k] if pred == true_labels])\n",
    "    return relevant / k\n",
    "\n",
    "def evaluate_map_at_25(predictions, true_labels, n=25):\n",
    "    \"\"\"\n",
    "    Evaluate Mean Average Precision at 25 (MAP@25).\n",
    "    predictions: Dictionary of predictions for each QuestionId_Answer.\n",
    "    true_labels: Dictionary of true MisconceptionId(s) for each QuestionId_Answer.\n",
    "    n: Number of predictions per observation (default is 25).\n",
    "    \"\"\"\n",
    "    map_score = 0\n",
    "    U = len(predictions)  # Number of observations (test set size)\n",
    "\n",
    "    for question_answer, pred_list in predictions.items():\n",
    "        true_set = true_labels.get(question_answer, [])\n",
    "        \n",
    "        if len(true_set) == 0:\n",
    "            continue  # Skip this if there are no true labels\n",
    "        true_set = np.argmax(true_set)\n",
    "        # Store the correct labels found\n",
    "        relevant_found = set()\n",
    "        avg_precision = 0\n",
    "        \n",
    "        for k in range(1, min(len(pred_list), n) + 1):\n",
    "            precision = 0\n",
    "            # Check if the prediction at rank k is relevant and not already counted\n",
    "            if pred_list[k - 1] == true_set and pred_list[k - 1] not in relevant_found:\n",
    "                relevant_found.add(pred_list[k - 1])\n",
    "                precision = calculate_precision_at_k(pred_list, true_set, k)\n",
    "            \n",
    "            # Precision at rank k: how many relevant items are in the top k\n",
    "            # precision = len(relevant_found) / k\n",
    "            avg_precision += precision\n",
    "        \n",
    "        map_score += avg_precision\n",
    "\n",
    "    # Compute Mean Average Precision (MAP@25)\n",
    "    return map_score / U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4df70025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:01:04.236565Z",
     "iopub.status.busy": "2024-12-10T01:01:04.236073Z",
     "iopub.status.idle": "2024-12-10T01:45:23.742834Z",
     "shell.execute_reply": "2024-12-10T01:45:23.741866Z"
    },
    "papermill": {
     "duration": 2659.515607,
     "end_time": "2024-12-10T01:45:23.744854",
     "exception": false,
     "start_time": "2024-12-10T01:01:04.229247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36acaeffddd24b359b0243e5d79313da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Loss: 8.2957\n",
      "Epoch 1 Validation Loss: 8.0293\n",
      "Saved best model at epoch 1.\n",
      "Epoch 2 Training Loss: 7.5896\n",
      "Epoch 2 Validation Loss: 8.0074\n",
      "Saved best model at epoch 2.\n",
      "Epoch 3 Training Loss: 7.2414\n",
      "Epoch 3 Validation Loss: 7.9878\n",
      "Saved best model at epoch 3.\n",
      "Epoch 4 Training Loss: 6.9016\n",
      "Epoch 4 Validation Loss: 7.7952\n",
      "Saved best model at epoch 4.\n",
      "Epoch 5 Training Loss: 6.5544\n",
      "Epoch 5 Validation Loss: 7.8265\n",
      "Epoch 6 Training Loss: 6.2338\n",
      "Epoch 6 Validation Loss: 7.6591\n",
      "Saved best model at epoch 6.\n",
      "Epoch 7 Training Loss: 5.9578\n",
      "Epoch 7 Validation Loss: 7.4592\n",
      "Saved best model at epoch 7.\n",
      "Epoch 8 Training Loss: 5.7242\n",
      "Epoch 8 Validation Loss: 7.6889\n",
      "Epoch 9 Training Loss: 5.5776\n",
      "Epoch 9 Validation Loss: 7.6189\n",
      "Epoch 10 Training Loss: 5.4626\n",
      "Epoch 10 Validation Loss: 7.7776\n"
     ]
    }
   ],
   "source": [
    "# Training loop with validation\n",
    "best_val_loss = float(\"inf\")\n",
    "best_model_path = \"best_model.pth\"\n",
    "\n",
    "for epoch in range(10):  # Number of epochs\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        predictions, true_labels = [], []\n",
    "        # Store MAP@25 results\n",
    "        all_predictions = {}\n",
    "        all_true_labels = {}\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # Get top 25 predictions (this can be adjusted for the actual number of misconceptions)\n",
    "        top_k_predictions = torch.topk(probabilities, k=25, dim=1).indices.cpu().numpy()\n",
    "        \n",
    "        # Store predictions and true labels\n",
    "        for i, question_id in enumerate(batch[\"QuestionId\"]):  # Ensure batch contains 'QuestionId'\n",
    "            question_answer = f\"{question_id}_{batch['AnswerLabel'][i]}\"  # Format QuestionId_Answer for unique identifier\n",
    "            \n",
    "            all_predictions[question_answer] = top_k_predictions[i]  # Store top 25 predicted misconception ids\n",
    "            all_true_labels[question_answer] = labels[i].cpu().numpy()  # Store true misconception ids\n",
    "\n",
    "        map_at_25 = evaluate_map_at_25(all_predictions, all_true_labels)\n",
    "        loss = loss_fn(logits, labels) + 0.5*(1- map_at_25)\n",
    "        # loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1} Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            predictions, true_labels = [], []\n",
    "            # Store MAP@25 results\n",
    "            all_predictions = {}\n",
    "            all_true_labels = {}\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "            # Get top 25 predictions (this can be adjusted for the actual number of misconceptions)\n",
    "            top_k_predictions = torch.topk(probabilities, k=25, dim=1).indices.cpu().numpy()\n",
    "            \n",
    "            # Store predictions and true labels\n",
    "            for i, question_id in enumerate(batch[\"QuestionId\"]):  # Ensure batch contains 'QuestionId'\n",
    "                question_answer = f\"{question_id}_{batch['AnswerLabel'][i]}\"  # Format QuestionId_Answer for unique identifier\n",
    "                \n",
    "                all_predictions[question_answer] = top_k_predictions[i]  # Store top 25 predicted misconception ids\n",
    "                all_true_labels[question_answer] = labels[i].cpu().numpy()  # Store true misconception ids\n",
    "\n",
    "            val_loss += (loss_fn(logits, labels) + 0.5*(1- map_at_25)).item()\n",
    "            # val_loss += outputs.loss.item()\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    print(f\"Epoch {epoch + 1} Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Saved best model at epoch {epoch + 1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a319b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:45:23.760812Z",
     "iopub.status.busy": "2024-12-10T01:45:23.760478Z",
     "iopub.status.idle": "2024-12-10T01:45:41.778795Z",
     "shell.execute_reply": "2024-12-10T01:45:41.777800Z"
    },
    "papermill": {
     "duration": 18.028553,
     "end_time": "2024-12-10T01:45:41.780549",
     "exception": false,
     "start_time": "2024-12-10T01:45:23.751996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@25: 0.1069\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have already loaded the model and test_dataloader\n",
    "model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "# Store MAP@25 results\n",
    "all_predictions = {}\n",
    "all_true_labels = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        test_loss += outputs.loss.item()\n",
    "\n",
    "        logits = outputs.logits\n",
    "        # print(logits.shape)\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # Get top 25 predictions (this can be adjusted for the actual number of misconceptions)\n",
    "        top_k_predictions = torch.topk(probabilities, k=25, dim=1).indices.cpu().numpy()\n",
    "        \n",
    "        # Store predictions and true labels\n",
    "        for i, question_id in enumerate(batch[\"QuestionId\"]):  # Ensure batch contains 'QuestionId'\n",
    "            question_answer = f\"{question_id}_{batch['AnswerLabel'][i]}\"  # Format QuestionId_Answer for unique identifier\n",
    "            \n",
    "            all_predictions[question_answer] = top_k_predictions[i]  # Store top 25 predicted misconception ids\n",
    "            all_true_labels[question_answer] = labels[i].cpu().numpy()  # Store true misconception ids\n",
    "\n",
    "# # Calculate MAP@25\n",
    "# def calculate_precision_at_k(predictions, true_labels, k):\n",
    "#     \"\"\"\n",
    "#     Calculate Precision at rank k.\n",
    "#     predictions: List of predicted MisconceptionId(s) for a particular QuestionId_Answer.\n",
    "#     true_labels: Set of correct MisconceptionId(s) for the same QuestionId_Answer.\n",
    "#     k: The rank at which precision is calculated.\n",
    "#     \"\"\"\n",
    "#     relevant = sum([1 for pred in predictions[:k] if pred in true_labels])\n",
    "#     return relevant / k\n",
    "\n",
    "# def evaluate_map_at_25(predictions, true_labels, n=25):\n",
    "#     \"\"\"\n",
    "#     Evaluate Mean Average Precision at 25 (MAP@25).\n",
    "#     predictions: Dictionary of predictions for each QuestionId_Answer.\n",
    "#     true_labels: Dictionary of true MisconceptionId(s) for each QuestionId_Answer.\n",
    "#     n: Number of predictions per observation (default is 25).\n",
    "#     \"\"\"\n",
    "#     map_score = 0\n",
    "#     U = len(predictions)  # Number of observations (test set size)\n",
    "\n",
    "#     for question_answer, pred_list in predictions.items():\n",
    "#         true_set = true_labels.get(question_answer, [])\n",
    "        \n",
    "#         if len(true_set) == 0:\n",
    "#             continue  # Skip this if there are no true labels\n",
    "        \n",
    "#         avg_precision = 0\n",
    "#         for k in range(1, min(len(pred_list), n) + 1):\n",
    "#             precision = calculate_precision_at_k(pred_list, true_set, k)\n",
    "#             avg_precision += precision\n",
    "        \n",
    "#         map_score += avg_precision / min(len(pred_list), n)\n",
    "\n",
    "#     # Compute Mean Average Precision (MAP@25)\n",
    "#     return map_score / U\n",
    "\n",
    "def calculate_precision_at_k(predictions, true_labels, k):\n",
    "    \"\"\"\n",
    "    Calculate Precision at rank k.\n",
    "    predictions: List of predicted MisconceptionId(s) for a particular QuestionId_Answer.\n",
    "    true_labels: Set of correct MisconceptionId(s) for the same QuestionId_Answer.\n",
    "    k: The rank at which precision is calculated.\n",
    "    \"\"\"\n",
    "    relevant = sum([1 for pred in predictions[:k] if pred == true_labels])\n",
    "    return relevant / k\n",
    "\n",
    "def evaluate_map_at_25(predictions, true_labels, n=25):\n",
    "    \"\"\"\n",
    "    Evaluate Mean Average Precision at 25 (MAP@25).\n",
    "    predictions: Dictionary of predictions for each QuestionId_Answer.\n",
    "    true_labels: Dictionary of true MisconceptionId(s) for each QuestionId_Answer.\n",
    "    n: Number of predictions per observation (default is 25).\n",
    "    \"\"\"\n",
    "    map_score = 0\n",
    "    U = len(predictions)  # Number of observations (test set size)\n",
    "\n",
    "    for question_answer, pred_list in predictions.items():\n",
    "        true_set = true_labels.get(question_answer, [])\n",
    "        \n",
    "        if len(true_set) == 0:\n",
    "            continue  # Skip this if there are no true labels\n",
    "        true_set = np.argmax(true_set)\n",
    "        # Store the correct labels found\n",
    "        relevant_found = set()\n",
    "        avg_precision = 0\n",
    "        \n",
    "        for k in range(1, min(len(pred_list), n) + 1):\n",
    "            precision = 0\n",
    "            # Check if the prediction at rank k is relevant and not already counted\n",
    "            if pred_list[k - 1] == true_set and pred_list[k - 1] not in relevant_found:\n",
    "                relevant_found.add(pred_list[k - 1])\n",
    "                precision = calculate_precision_at_k(pred_list, true_set, k)\n",
    "            \n",
    "            # Precision at rank k: how many relevant items are in the top k\n",
    "            # precision = len(relevant_found) / k\n",
    "            avg_precision += precision\n",
    "        \n",
    "        map_score += avg_precision\n",
    "\n",
    "    # Compute Mean Average Precision (MAP@25)\n",
    "    return map_score / U\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate MAP@25\n",
    "map_at_25 = evaluate_map_at_25(all_predictions, all_true_labels)\n",
    "test_loss /= len(test_dataloader)\n",
    "# print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"MAP@25: {map_at_25:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7bd63ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:45:41.795644Z",
     "iopub.status.busy": "2024-12-10T01:45:41.795370Z",
     "iopub.status.idle": "2024-12-10T01:45:41.800339Z",
     "shell.execute_reply": "2024-12-10T01:45:41.799646Z"
    },
    "papermill": {
     "duration": 0.01408,
     "end_time": "2024-12-10T01:45:41.801798",
     "exception": false,
     "start_time": "2024-12-10T01:45:41.787718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-1#MAP@3-Metric\n",
    "def map_at_25(predictions, labels):\n",
    "    map_sum = 0\n",
    "    # U = len(predictions)  # Number of observations (test set size)\n",
    "\n",
    "    for question_answer, pred_list in predictions.items():\n",
    "        true_set1 = labels.get(question_answer, [])\n",
    "        true_set = np.argmax(true_set1)\n",
    "        # print(true_set1)\n",
    "        # print(pred_list)\n",
    "    # for x, y in zip(predictions, labels):\n",
    "    #     z = [1 / i if y == j else 0 for i, j in zip(range(1, 26), x)]\n",
    "        z = [1 / i if true_set == j else 0 for i, j in zip(range(1, 26), pred_list)]\n",
    "        map_sum += np.sum(z)\n",
    "    return map_sum / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71472b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:45:41.816000Z",
     "iopub.status.busy": "2024-12-10T01:45:41.815672Z",
     "iopub.status.idle": "2024-12-10T01:45:41.836842Z",
     "shell.execute_reply": "2024-12-10T01:45:41.835983Z"
    },
    "papermill": {
     "duration": 0.029912,
     "end_time": "2024-12-10T01:45:41.838385",
     "exception": false,
     "start_time": "2024-12-10T01:45:41.808473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10692927401654044"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_at_25_score = map_at_25(all_predictions, all_true_labels)\n",
    "map_at_25_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ec48953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:45:41.853242Z",
     "iopub.status.busy": "2024-12-10T01:45:41.853004Z",
     "iopub.status.idle": "2024-12-10T01:45:41.856412Z",
     "shell.execute_reply": "2024-12-10T01:45:41.855692Z"
    },
    "papermill": {
     "duration": 0.012588,
     "end_time": "2024-12-10T01:45:41.857911",
     "exception": false,
     "start_time": "2024-12-10T01:45:41.845323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffbe9310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:45:41.872892Z",
     "iopub.status.busy": "2024-12-10T01:45:41.872389Z",
     "iopub.status.idle": "2024-12-10T01:45:41.875466Z",
     "shell.execute_reply": "2024-12-10T01:45:41.874791Z"
    },
    "papermill": {
     "duration": 0.012509,
     "end_time": "2024-12-10T01:45:41.877135",
     "exception": false,
     "start_time": "2024-12-10T01:45:41.864626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81f90147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:45:41.891877Z",
     "iopub.status.busy": "2024-12-10T01:45:41.891630Z",
     "iopub.status.idle": "2024-12-10T01:45:41.895972Z",
     "shell.execute_reply": "2024-12-10T01:45:41.895164Z"
    },
    "papermill": {
     "duration": 0.013703,
     "end_time": "2024-12-10T01:45:41.897645",
     "exception": false,
     "start_time": "2024-12-10T01:45:41.883942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class PredictionDataset(Dataset):\n",
    "#     def __init__(self, question_ids, answer_labels, texts, tokenizer, max_length=128):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             question_ids (list): List of Question IDs.\n",
    "#             answer_labels (list): List of Answer Labels (e.g., A, B, C, D).\n",
    "#             texts (list): List of question texts.\n",
    "#             labels (list): List of true Misconception IDs.\n",
    "#             tokenizer (transformers tokenizer): Tokenizer to encode the text.\n",
    "#             max_length (int, optional): Max sequence length for tokenization. Defaults to 128.\n",
    "#         \"\"\"\n",
    "#         self.question_ids = question_ids\n",
    "#         self.answer_labels = answer_labels\n",
    "#         self.texts = texts\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         question_id = self.question_ids[idx]\n",
    "#         answer_label = self.answer_labels[idx]\n",
    "#         text = self.texts[idx]\n",
    "\n",
    "#         # Assuming the `text` is just the question text; answer is inferred from `answer_label`\n",
    "#         question = text  # In case answer text is separate, modify as needed\n",
    "\n",
    "#         # Tokenize the question text\n",
    "#         tokens = self.tokenizer(\n",
    "#             question,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors=\"pt\",\n",
    "#             return_special_tokens_mask=True,  # Ensures correct use of [SEP]\n",
    "#         )\n",
    "\n",
    "#         return {\n",
    "#             \"input_ids\": tokens[\"input_ids\"].squeeze(),\n",
    "#             \"attention_mask\": tokens[\"attention_mask\"].squeeze(),\n",
    "#             \"QuestionId\": question_id,  # Include the Question ID\n",
    "#             \"AnswerLabel\": answer_label  # Include the Answer label (A, B, C, D)\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29874534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:45:41.912337Z",
     "iopub.status.busy": "2024-12-10T01:45:41.912103Z",
     "iopub.status.idle": "2024-12-10T01:45:41.915668Z",
     "shell.execute_reply": "2024-12-10T01:45:41.915000Z"
    },
    "papermill": {
     "duration": 0.012724,
     "end_time": "2024-12-10T01:45:41.917186",
     "exception": false,
     "start_time": "2024-12-10T01:45:41.904462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Preprocess data\n",
    "# def preprocess_testdata(df):\n",
    "#     data = []\n",
    "#     for _, row in df.iterrows():\n",
    "#         for option in [\"A\", \"B\", \"C\", \"D\"]:  # Only incorrect answers\n",
    "#             # if row['CorrectAnswer'] != option:\n",
    "#             input_text = f\"Question: {row['QuestionText']} | Answer: {row[f'Answer{option}Text']}\"\n",
    "#             # label = row[f\"Misconception{option}Id\"]\n",
    "#             questionid = f\"{row['QuestionId']}\"\n",
    "#             answer = f\"{option}\"\n",
    "#             data.append((questionid, answer, input_text))\n",
    "#     return pd.DataFrame(data, columns=[\"QuestionId\",\"Answer\", \"text\"])\n",
    "\n",
    "# real_test_data = preprocess_testdata(real_test_df)\n",
    "# real_test_data.dropna(inplace = True)\n",
    "\n",
    "# # # Combine into DataFrames\n",
    "# # train_data = pd.DataFrame(train_data, columns=[\"text\", \"label\"])\n",
    "# # val_data = pd.DataFrame(val_data, columns=[\"text\", \"label\"])\n",
    "# # test_data = pd.DataFrame(test_data, columns=[\"text\", \"label\"])\n",
    "\n",
    "# # Convert labels to multi-hot encoding\n",
    "# # all_labels = sorted(misconception_df[\"MisconceptionId\"].unique())  # Get all unique labels\n",
    "# # mlb = MultiLabelBinarizer(classes=all_labels)\n",
    "\n",
    "# # real_test_labels = mlb.transform([[label] for label in real_test_data[\"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d01a1215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:45:41.933444Z",
     "iopub.status.busy": "2024-12-10T01:45:41.933195Z",
     "iopub.status.idle": "2024-12-10T01:45:41.936491Z",
     "shell.execute_reply": "2024-12-10T01:45:41.935719Z"
    },
    "papermill": {
     "duration": 0.012871,
     "end_time": "2024-12-10T01:45:41.938180",
     "exception": false,
     "start_time": "2024-12-10T01:45:41.925309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create datasets\n",
    "# real_test_dataset = PredictionDataset(real_test_data[\"QuestionId\"].tolist(), real_test_data[\"Answer\"].tolist(), real_test_data[\"text\"].tolist(), tokenizer)\n",
    "\n",
    "# # DataLoader for batching\n",
    "# real_test_dataloader = DataLoader(real_test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52af00ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:45:41.952826Z",
     "iopub.status.busy": "2024-12-10T01:45:41.952457Z",
     "iopub.status.idle": "2024-12-10T01:45:41.956589Z",
     "shell.execute_reply": "2024-12-10T01:45:41.955820Z"
    },
    "papermill": {
     "duration": 0.013301,
     "end_time": "2024-12-10T01:45:41.958188",
     "exception": false,
     "start_time": "2024-12-10T01:45:41.944887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Assuming you have already loaded the model and test_dataloader\n",
    "# model.load_state_dict(torch.load(best_model_path))\n",
    "# model.eval()\n",
    "\n",
    "# test_loss = 0\n",
    "# predictions, true_labels = [], []\n",
    "\n",
    "# # Store MAP@25 results\n",
    "# all_predictions = {}\n",
    "# all_true_labels = {}\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch in real_test_dataloader:\n",
    "#         input_ids = batch[\"input_ids\"].to(device)\n",
    "#         attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#         # labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "#         # Forward pass\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask)\n",
    "#         # test_loss += outputs.loss.item()\n",
    "\n",
    "#         logits = outputs.logits\n",
    "#         probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "#         # Get top 25 predictions (this can be adjusted for the actual number of misconceptions)\n",
    "#         top_k_predictions = torch.topk(probabilities, k=25, dim=1).indices.cpu().numpy()\n",
    "        \n",
    "#         # Store predictions and true labels\n",
    "#         for i, question_id in enumerate(batch[\"QuestionId\"]):  # Ensure batch contains 'QuestionId'\n",
    "#             question_answer = f\"{question_id}_{batch['AnswerLabel'][i]}\"  # Format QuestionId_Answer for unique identifier\n",
    "            \n",
    "#             all_predictions[question_answer] = top_k_predictions[i]  # Store top 25 predicted misconception ids\n",
    "#             all_true_labels[question_answer] = labels[i].cpu().numpy()  # Store true misconception ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b23d5b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:45:41.972866Z",
     "iopub.status.busy": "2024-12-10T01:45:41.972407Z",
     "iopub.status.idle": "2024-12-10T01:45:41.975753Z",
     "shell.execute_reply": "2024-12-10T01:45:41.975123Z"
    },
    "papermill": {
     "duration": 0.012452,
     "end_time": "2024-12-10T01:45:41.977478",
     "exception": false,
     "start_time": "2024-12-10T01:45:41.965026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Convert each NumPy array to a string\n",
    "# data_str = [(key, np.array2string(value)) for key, value in all_predictions.items()]\n",
    "# df = pd.DataFrame(data_str, columns=[\"QuestionId_Answer\", \"MisconceptionId\"])\n",
    "# df.to_csv(\"submission.csv\", columns=[\"QuestionId_Answer\", \"MisconceptionId\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baf39868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:45:41.992075Z",
     "iopub.status.busy": "2024-12-10T01:45:41.991835Z",
     "iopub.status.idle": "2024-12-10T01:45:41.995043Z",
     "shell.execute_reply": "2024-12-10T01:45:41.994324Z"
    },
    "papermill": {
     "duration": 0.012418,
     "end_time": "2024-12-10T01:45:41.996663",
     "exception": false,
     "start_time": "2024-12-10T01:45:41.984245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.read_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9738540,
     "sourceId": 82695,
     "sourceType": "competition"
    },
    {
     "datasetId": 2663421,
     "sourceId": 4620664,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4105336,
     "sourceId": 7118215,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 133071,
     "modelInstanceId": 108753,
     "sourceId": 129073,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2709.711403,
   "end_time": "2024-12-10T01:45:45.359880",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-10T01:00:35.648477",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00462306733640e1936a715a1b77d95c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6180b48a166347ac9c3658afa3df9379",
       "placeholder": "​",
       "style": "IPY_MODEL_c87faad60ce04a84b6ba28a11504a809",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "05bc8890da6f41bc8fc0bd3609262732": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0aeb0bb0ce3e4a6ab5d4972a60c6f4c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0deb8c03726946ea92794b0aec2651f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d6103d6eb2f744738cfa0fcf841168db",
       "placeholder": "​",
       "style": "IPY_MODEL_b415f085b0c1460889dafd340a801e65",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "0e2351a5e2794d03b2e3d3fff11340f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c50971f2f1b4df89a9d713f015145ed",
       "placeholder": "​",
       "style": "IPY_MODEL_cc71a5be8cfd4f1299ba7f5df3bd6437",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "1ba8f814033d408c81f859859cbd93e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d3f74e4599f4cd5989b562b80b053e4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36acaeffddd24b359b0243e5d79313da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0deb8c03726946ea92794b0aec2651f1",
        "IPY_MODEL_ab40cb08f2de430e8cea8352ed0b6738",
        "IPY_MODEL_5fb0344ccb8d4c5385cc47cea83c9286"
       ],
       "layout": "IPY_MODEL_4deb50ca9999488abe787259bb22f4d4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "39637dee53224f98b357ac49bcae05f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "39ca09a23bf9476eb77e041d2ba23e59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a2882ce43bb0435f932cb704cdd8b925",
       "placeholder": "​",
       "style": "IPY_MODEL_b5eec1694a9b4d12ac5e044d10f083fa",
       "tabbable": null,
       "tooltip": null,
       "value": " 579/579 [00:00&lt;00:00, 76.1kB/s]"
      }
     },
     "3c396c5b8c454a4fb5a3a7151bff1f37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d3f74e4599f4cd5989b562b80b053e4",
       "placeholder": "​",
       "style": "IPY_MODEL_39637dee53224f98b357ac49bcae05f0",
       "tabbable": null,
       "tooltip": null,
       "value": " 52.0/52.0 [00:00&lt;00:00, 5.82kB/s]"
      }
     },
     "3d29aceab5a44f728ba7889d0e6e5088": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_45d9e064d28a497f8234ddf5cf3e6d54",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_76314b64cc1e4a47a042a87764c78861",
       "tabbable": null,
       "tooltip": null,
       "value": 52.0
      }
     },
     "431adabf86f44edfb283372861452ffb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "459bebc44ba4438da15fd4e6457d2dbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0e2351a5e2794d03b2e3d3fff11340f7",
        "IPY_MODEL_60a1b2727d8649e1b4db1bfe4f6835a5",
        "IPY_MODEL_d5a90ff7816849c0b12c83f0d4230c7b"
       ],
       "layout": "IPY_MODEL_ea60d7099403430b9ff45bf0fd9c4c50",
       "tabbable": null,
       "tooltip": null
      }
     },
     "45d9e064d28a497f8234ddf5cf3e6d54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4626c1422f09493486279a8bbed1f330": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f6c0971fb0524937b0986d7773d6275c",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b381514d525c419bbeb313611c308a86",
       "tabbable": null,
       "tooltip": null,
       "value": 2464616.0
      }
     },
     "480a41c4ac2f432aaa37f44c1a334a8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4deb50ca9999488abe787259bb22f4d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "566cd6ab8a464a918037b11358ac4d7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8f3b40636966468e8ce48cd20bb86711",
       "placeholder": "​",
       "style": "IPY_MODEL_5b8483a2e2154f8883b1852ad83f2b62",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "5b8483a2e2154f8883b1852ad83f2b62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5ea4b381b27b40a883ee39e72aa64c1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5fb0344ccb8d4c5385cc47cea83c9286": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f319b2951b8a45bcbf5081063053e963",
       "placeholder": "​",
       "style": "IPY_MODEL_b34afcfac4534d938506c640fb9b705b",
       "tabbable": null,
       "tooltip": null,
       "value": " 371M/371M [00:01&lt;00:00, 239MB/s]"
      }
     },
     "60a1b2727d8649e1b4db1bfe4f6835a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e0a610fab73b4b5abdbc9b89b173d044",
       "max": 371146213.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d675227a2fe34beea0cbf8f658bc77e3",
       "tabbable": null,
       "tooltip": null,
       "value": 371146213.0
      }
     },
     "60ed46338ac3492592263b97450863fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5ea4b381b27b40a883ee39e72aa64c1e",
       "placeholder": "​",
       "style": "IPY_MODEL_0aeb0bb0ce3e4a6ab5d4972a60c6f4c1",
       "tabbable": null,
       "tooltip": null,
       "value": "spm.model: 100%"
      }
     },
     "6180b48a166347ac9c3658afa3df9379": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6dff29f1a62c4fccaf8151201f283674": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6e748b07c51643b08c45844cc89cfb53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_431adabf86f44edfb283372861452ffb",
       "max": 579.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c833d48378174c2c852dbe067087d4d1",
       "tabbable": null,
       "tooltip": null,
       "value": 579.0
      }
     },
     "76314b64cc1e4a47a042a87764c78861": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "87c915aeb68c41ff8cc70e4983c8f518": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_60ed46338ac3492592263b97450863fa",
        "IPY_MODEL_4626c1422f09493486279a8bbed1f330",
        "IPY_MODEL_fdb74947fa614b81bc979e2045a1c779"
       ],
       "layout": "IPY_MODEL_1ba8f814033d408c81f859859cbd93e7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8c50971f2f1b4df89a9d713f015145ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f3b40636966468e8ce48cd20bb86711": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8fb2670858db45cfadf5efcf0ed2a46f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_00462306733640e1936a715a1b77d95c",
        "IPY_MODEL_6e748b07c51643b08c45844cc89cfb53",
        "IPY_MODEL_39ca09a23bf9476eb77e041d2ba23e59"
       ],
       "layout": "IPY_MODEL_ff4c1a20526e4512b6aedbaa059b9f76",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9782bcb6754b4b61bd31fc95e5c3770b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a2882ce43bb0435f932cb704cdd8b925": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9a6db1c44bf4a74966643ea899bee64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab40cb08f2de430e8cea8352ed0b6738": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_480a41c4ac2f432aaa37f44c1a334a8e",
       "max": 371101258.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a9a6db1c44bf4a74966643ea899bee64",
       "tabbable": null,
       "tooltip": null,
       "value": 371101258.0
      }
     },
     "b34afcfac4534d938506c640fb9b705b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b381514d525c419bbeb313611c308a86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b415f085b0c1460889dafd340a801e65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b5eec1694a9b4d12ac5e044d10f083fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "be68f17f4d204becab4f09366bbb0c45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c833d48378174c2c852dbe067087d4d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c87faad60ce04a84b6ba28a11504a809": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cc71a5be8cfd4f1299ba7f5df3bd6437": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d46c68d41c834cdfb7887c967ef904b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_566cd6ab8a464a918037b11358ac4d7a",
        "IPY_MODEL_3d29aceab5a44f728ba7889d0e6e5088",
        "IPY_MODEL_3c396c5b8c454a4fb5a3a7151bff1f37"
       ],
       "layout": "IPY_MODEL_be68f17f4d204becab4f09366bbb0c45",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d5a90ff7816849c0b12c83f0d4230c7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_eba5eab9118241c2bc4c844201ec4780",
       "placeholder": "​",
       "style": "IPY_MODEL_6dff29f1a62c4fccaf8151201f283674",
       "tabbable": null,
       "tooltip": null,
       "value": " 371M/371M [00:01&lt;00:00, 222MB/s]"
      }
     },
     "d6103d6eb2f744738cfa0fcf841168db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d675227a2fe34beea0cbf8f658bc77e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e0a610fab73b4b5abdbc9b89b173d044": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea60d7099403430b9ff45bf0fd9c4c50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eba5eab9118241c2bc4c844201ec4780": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f319b2951b8a45bcbf5081063053e963": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6c0971fb0524937b0986d7773d6275c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fdb74947fa614b81bc979e2045a1c779": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_05bc8890da6f41bc8fc0bd3609262732",
       "placeholder": "​",
       "style": "IPY_MODEL_9782bcb6754b4b61bd31fc95e5c3770b",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.46M/2.46M [00:00&lt;00:00, 36.2MB/s]"
      }
     },
     "ff4c1a20526e4512b6aedbaa059b9f76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
